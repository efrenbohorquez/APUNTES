% ===============================================
% APÉNDICE B: DATOS Y RESULTADOS COMPLEMENTARIOS
% ===============================================

\chapter{Datos y Resultados Complementarios}
\label{ap:datos_resultados}

% Introducción al apéndice
Este apéndice presenta información complementaria que sustenta los resultados principales de la investigación, incluyendo datasets utilizados, métricas detalladas, configuraciones de modelos y análisis estadísticos adicionales.

% ===============================================
% SECCIÓN B.1: DESCRIPCIÓN DETALLADA DE DATASETS
% ===============================================

\section{Descripción Detallada de Datasets}
\label{sec:datasets_detallados}

\subsection{Dataset Principal}
\label{subsec:dataset_principal}

% Tabla con estadísticas descriptivas del dataset
\begin{table}[htbp]
    \centering
    \caption{Estadísticas Descriptivas del Dataset Principal}
    \label{tab:estadisticas_dataset}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Variable} & \textbf{Tipo} & \textbf{Valores Únicos} & \textbf{Valores Nulos} & \textbf{Distribución} \\
        \hline
        ID & Numérico & 50,000 & 0 & Secuencial \\
        \hline
        Edad & Numérico & 82 & 150 & Normal \\
        \hline
        Género & Categórico & 3 & 75 & 52\% F, 47\% M, 1\% O \\
        \hline
        Ingresos & Numérico & 45,678 & 892 & Log-normal \\
        \hline
        Región & Categórico & 12 & 23 & Uniforme \\
        \hline
        Target & Binario & 2 & 0 & 35\% Positivo \\
        \hline
    \end{tabular}
\end{table}

\subsection{Datasets de Validación}
\label{subsec:datasets_validacion}

\begin{itemize}
    \item \textbf{Dataset de Test}: 15,000 registros con distribución similar al dataset principal
    \item \textbf{Dataset de Validación Temporal}: 5,000 registros de un período posterior
    \item \textbf{Dataset Benchmark}: Dataset público estándar para comparación (UCI ML Repository)
\end{itemize}

% ===============================================
% SECCIÓN B.2: CONFIGURACIONES DE MODELOS
% ===============================================

\section{Configuraciones Detalladas de Modelos}
\label{sec:configuraciones_modelos}

\subsection{Random Forest}
\label{subsec:config_rf}

\begin{lstlisting}[language=Python, caption=Configuración Random Forest Óptima]
# Configuración encontrada mediante GridSearchCV
rf_config = {
    'n_estimators': 500,
    'max_depth': 15,
    'min_samples_split': 5,
    'min_samples_leaf': 2,
    'max_features': 'sqrt',
    'bootstrap': True,
    'random_state': 42,
    'n_jobs': -1,
    'class_weight': 'balanced'
}
\end{lstlisting}

\subsection{XGBoost}
\label{subsec:config_xgb}

\begin{lstlisting}[language=Python, caption=Configuración XGBoost Óptima]
# Parámetros optimizados con Optuna
xgb_config = {
    'objective': 'binary:logistic',
    'eval_metric': 'auc',
    'max_depth': 8,
    'learning_rate': 0.05,
    'n_estimators': 1000,
    'subsample': 0.8,
    'colsample_bytree': 0.85,
    'reg_alpha': 0.1,
    'reg_lambda': 1.0,
    'scale_pos_weight': 1.85,
    'random_state': 42
}
\end{lstlisting}

\subsection{Red Neuronal}
\label{subsec:config_nn}

\begin{lstlisting}[language=Python, caption=Arquitectura de Red Neuronal]
# Arquitectura de la red neuronal optimizada
model = Sequential([
    Dense(512, activation='relu', input_shape=(n_features,)),
    BatchNormalization(),
    Dropout(0.3),
    
    Dense(256, activation='relu'),
    BatchNormalization(),
    Dropout(0.25),
    
    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.2),
    
    Dense(64, activation='relu'),
    Dropout(0.15),
    
    Dense(1, activation='sigmoid')
])

# Configuración de entrenamiento
compile_config = {
    'optimizer': Adam(learning_rate=0.001),
    'loss': 'binary_crossentropy',
    'metrics': ['accuracy', 'precision', 'recall']
}
\end{lstlisting}

% ===============================================
% SECCIÓN B.3: RESULTADOS DETALLADOS POR MODELO
% ===============================================

\section{Resultados Detallados por Modelo}
\label{sec:resultados_detallados}

\subsection{Métricas de Evaluación Completas}
\label{subsec:metricas_completas}

% Tabla con todas las métricas
\begin{table}[htbp]
    \centering
    \caption{Métricas Completas de Evaluación por Modelo}
    \label{tab:metricas_completas}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|}
        \hline
        \textbf{Modelo} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{AUC-ROC} & \textbf{AUC-PR} & \textbf{Tiempo (s)} & \textbf{Memoria (MB)} \\
        \hline
        Logistic Regression & 0.823 & 0.798 & 0.756 & 0.776 & 0.887 & 0.743 & 2.3 & 45 \\
        \hline
        Random Forest & 0.856 & 0.834 & 0.812 & 0.823 & 0.923 & 0.806 & 45.2 & 512 \\
        \hline
        XGBoost & 0.867 & 0.851 & 0.823 & 0.837 & 0.934 & 0.821 & 67.8 & 256 \\
        \hline
        Red Neuronal & 0.871 & 0.856 & 0.831 & 0.843 & 0.938 & 0.827 & 234.5 & 1024 \\
        \hline
        Ensemble & \textbf{0.879} & \textbf{0.863} & \textbf{0.842} & \textbf{0.852} & \textbf{0.945} & \textbf{0.834} & 89.3 & 892 \\
        \hline
    \end{tabular}
    }
\end{table}

\subsection{Matrices de Confusión}
\label{subsec:matrices_confusion}

% Aquí irían las matrices de confusión para cada modelo
% Ejemplo para el mejor modelo:

\begin{table}[htbp]
    \centering
    \caption{Matriz de Confusión - Modelo Ensemble (Dataset de Test)}
    \label{tab:confusion_ensemble}
    \begin{tabular}{|c|c|c|}
        \hline
        & \textbf{Predicho Negativo} & \textbf{Predicho Positivo} \\
        \hline
        \textbf{Real Negativo} & 8,234 & 516 \\
        \hline
        \textbf{Real Positivo} & 847 & 4,403 \\
        \hline
    \end{tabular}
\end{table}

% ===============================================
% SECCIÓN B.4: ANÁLISIS DE FEATURES
% ===============================================

\section{Análisis Detallado de Features}
\label{sec:analisis_features}

\subsection{Importancia de Variables}
\label{subsec:importancia_variables}

% Tabla con importancia de features
\begin{table}[htbp]
    \centering
    \caption{Top 15 Features más Importantes (Random Forest)}
    \label{tab:feature_importance}
    \begin{tabular}{|l|c|c|}
        \hline
        \textbf{Feature} & \textbf{Importancia} & \textbf{Importancia Normalizada} \\
        \hline
        historial\_transacciones & 0.156 & 1.000 \\
        \hline
        edad\_cliente & 0.134 & 0.859 \\
        \hline
        ingresos\_anuales & 0.098 & 0.628 \\
        \hline
        score\_crediticio & 0.087 & 0.558 \\
        \hline
        tiempo\_cliente & 0.076 & 0.487 \\
        \hline
        productos\_activos & 0.065 & 0.417 \\
        \hline
        frecuencia\_uso & 0.058 & 0.372 \\
        \hline
        ubicacion\_geografica & 0.045 & 0.288 \\
        \hline
        canal\_preferido & 0.039 & 0.250 \\
        \hline
        satisfaccion\_cliente & 0.034 & 0.218 \\
        \hline
        interacciones\_soporte & 0.031 & 0.199 \\
        \hline
        dispositivo\_principal & 0.028 & 0.179 \\
        \hline
        promociones\_usadas & 0.025 & 0.160 \\
        \hline
        referencias\_sociales & 0.022 & 0.141 \\
        \hline
        estado\_civil & 0.019 & 0.122 \\
        \hline
    \end{tabular}
\end{table}

\subsection{Análisis de Correlaciones}
\label{subsec:correlaciones}

% Descripción de correlaciones importantes encontradas
Las correlaciones más significativas encontradas en el análisis exploratorio:

\begin{itemize}
    \item \textbf{historial\_transacciones} vs \textbf{target}: r = 0.68 (correlación fuerte positiva)
    \item \textbf{edad\_cliente} vs \textbf{ingresos\_anuales}: r = 0.45 (correlación moderada positiva)
    \item \textbf{score\_crediticio} vs \textbf{productos\_activos}: r = 0.52 (correlación moderada positiva)
    \item \textbf{frecuencia\_uso} vs \textbf{satisfaccion\_cliente}: r = 0.39 (correlación moderada positiva)
\end{itemize}

% ===============================================
% SECCIÓN B.5: VALIDACIÓN CRUZADA DETALLADA
% ===============================================

\section{Validación Cruzada Detallada}
\label{sec:validacion_cruzada}

\subsection{Resultados por Fold}
\label{subsec:resultados_fold}

% Tabla con resultados de validación cruzada
\begin{table}[htbp]
    \centering
    \caption{Resultados de Validación Cruzada (K=5) - Modelo Final}
    \label{tab:cv_results}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{Fold} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
        \hline
        1 & 0.874 & 0.859 & 0.838 & 0.848 \\
        \hline
        2 & 0.881 & 0.867 & 0.845 & 0.856 \\
        \hline
        3 & 0.876 & 0.862 & 0.841 & 0.851 \\
        \hline
        4 & 0.883 & 0.868 & 0.847 & 0.857 \\
        \hline
        5 & 0.878 & 0.864 & 0.843 & 0.853 \\
        \hline
        \textbf{Media} & \textbf{0.878} & \textbf{0.864} & \textbf{0.843} & \textbf{0.853} \\
        \hline
        \textbf{Std} & \textbf{0.003} & \textbf{0.004} & \textbf{0.003} & \textbf{0.004} \\
        \hline
    \end{tabular}
\end{table}

% ===============================================
% SECCIÓN B.6: ANÁLISIS DE ERRORES
% ===============================================

\section{Análisis de Errores y Casos Límite}
\label{sec:analisis_errores}

\subsection{Caracterización de Falsos Positivos}
\label{subsec:falsos_positivos}

Análisis de los casos donde el modelo predice incorrectamente la clase positiva:

\begin{itemize}
    \item \textbf{Patrón 1}: Clientes jóvenes con historial limitado (23\% de FP)
    \item \textbf{Patrón 2}: Cambios recientes en comportamiento (19\% de FP)
    \item \textbf{Patrón 3}: Datos inconsistentes o ruidosos (15\% de FP)
    \item \textbf{Otros patrones}: (43\% de FP)
\end{itemize}

\subsection{Caracterización de Falsos Negativos}
\label{subsec:falsos_negativos}

Análisis de los casos donde el modelo no detecta correctamente la clase positiva:

\begin{itemize}
    \item \textbf{Patrón 1}: Comportamiento atípico no capturado por features (31\% de FN)
    \item \textbf{Patrón 2}: Clientes en transición de segmento (24\% de FN)
    \item \textbf{Patrón 3}: Eventos externos no modelados (18\% de FN)
    \item \textbf{Otros patrones}: (27\% de FN)
\end{itemize}

% ===============================================
% SECCIÓN B.7: CONFIGURACIÓN DEL ENTORNO
% ===============================================

\section{Configuración del Entorno de Desarrollo}
\label{sec:entorno_desarrollo}

\subsection{Especificaciones del Hardware}
\label{subsec:hardware}

\begin{itemize}
    \item \textbf{Procesador}: Intel i7-10700K @ 3.80GHz (8 cores, 16 threads)
    \item \textbf{Memoria RAM}: 32 GB DDR4 3200MHz
    \item \textbf{GPU}: NVIDIA RTX 3080 (10GB VRAM) - para modelos de deep learning
    \item \textbf{Almacenamiento}: SSD NVMe 1TB para datos y modelos
    \item \textbf{Sistema Operativo}: Ubuntu 20.04 LTS
\end{itemize}

\subsection{Versiones de Software}
\label{subsec:software}

\begin{lstlisting}[language=bash, caption=Versiones de Paquetes Principales]
# Python y librerías principales
Python: 3.9.7
NumPy: 1.21.2
Pandas: 1.3.3
Scikit-learn: 1.0.2
XGBoost: 1.5.1
TensorFlow: 2.7.0
Keras: 2.7.0

# Visualización y análisis
Matplotlib: 3.4.3
Seaborn: 0.11.2
Plotly: 5.3.1

# Utilidades
Jupyter: 1.0.0
optuna: 2.10.0
mlflow: 1.20.2
\end{lstlisting}

% ===============================================
% SECCIÓN B.8: INSTRUCCIONES DE REPRODUCIBILIDAD
% ===============================================

\section{Instrucciones de Reproducibilidad}
\label{sec:reproducibilidad}

\subsection{Pasos para Reproducir los Resultados}
\label{subsec:pasos_reproduccion}

\begin{enumerate}
    \item \textbf{Preparación del entorno}:
    \begin{lstlisting}[language=bash]
# Crear entorno virtual
python -m venv tesis_env
source tesis_env/bin/activate  # Linux/Mac
# tesis_env\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements.txt
    \end{lstlisting}
    
    \item \textbf{Descarga y preparación de datos}:
    \begin{lstlisting}[language=bash]
# Ejecutar script de descarga
python scripts/download_data.py

# Preprocesar datos
python scripts/preprocess_data.py --config config/preprocess.yaml
    \end{lstlisting}
    
    \item \textbf{Entrenamiento de modelos}:
    \begin{lstlisting}[language=bash]
# Entrenar todos los modelos
python scripts/train_models.py --experiment final_experiment

# O entrenar modelo específico
python scripts/train_single_model.py --model xgboost --config config/xgb_final.yaml
    \end{lstlisting}
    
    \item \textbf{Evaluación y resultados}:
    \begin{lstlisting}[language=bash]
# Generar evaluaciones
python scripts/evaluate_models.py --experiment final_experiment

# Generar reportes
python scripts/generate_reports.py --output reports/
    \end{lstlisting}
\end{enumerate}

\subsection{Semillas Aleatorias}
\label{subsec:semillas}

Para garantizar la reproducibilidad completa, se utilizaron las siguientes semillas:

\begin{lstlisting}[language=Python, caption=Configuración de Semillas Aleatorias]
import random
import numpy as np
import tensorflow as tf
from sklearn.utils import check_random_state

# Semilla principal
RANDOM_SEED = 42

# Configurar todas las fuentes de aleatoriedad
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

# Para scikit-learn
random_state = check_random_state(RANDOM_SEED)
\end{lstlisting}

Este apéndice proporciona toda la información necesaria para comprender, validar y reproducir los resultados obtenidos en esta investigación.
